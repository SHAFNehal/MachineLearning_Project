{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/cc/MLFP'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from scipy import ndimage\n",
    "\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "X = np.array(train_data.ix[:,0:1])\n",
    "Y = np.array(train_data.ix[:,1:2])\n",
    "\n",
    "root = '/home/cc/MLFP/crop_images'\n",
    "image_path_train = []\n",
    "for i, j in enumerate(X):\n",
    "    image_path_train.append(os.path.join(root+'/'+j[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = Y[:,0]\n",
    "\n",
    "num_labels = 196\n",
    "\n",
    "def reformat(labels):\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    labels[labels > 0.5] = 1 #0.9\n",
    "    labels[labels < 0.5] = 0 #0.1\n",
    "    return labels\n",
    "\n",
    "labels = reformat(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((11305, 227, 227, 3), dtype=np.float32)\n",
    "for i, path in enumerate(image_path_train):\n",
    "    try:\n",
    "        #print(path)\n",
    "        X_train[i,:,:,:] = mpimg.imread(path).astype(float)\n",
    "    except IOError as e:\n",
    "        print('Could not read:', path, ':', e, 'it\\'s ok, skipping.')\n",
    "        print('The index is:', i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = { 'data': X_train,\n",
    "          'labels': labels}\n",
    "\n",
    "pickle.dump(dataset,open(\"Train.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "train_data = pd.read_csv(\"test.csv\")\n",
    "X = np.array(train_data.ix[:,0:1])\n",
    "Y = np.array(train_data.ix[:,1:2])\n",
    "\n",
    "root = '/home/cc/MLFP/crop_images'\n",
    "image_path_test = []\n",
    "for i, j in enumerate(X):\n",
    "    image_path_test.append(os.path.join(root+'/'+j[0])) \n",
    "    \n",
    "label = Y[:,0]\n",
    "\n",
    "num_labels = 196\n",
    "\n",
    "def reformat(labels):\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    labels[labels > 0.5] = 1 # 0.9\n",
    "    labels[labels < 0.5] = 0 # 0.1\n",
    "    return labels\n",
    "\n",
    "labels = reformat(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.zeros((4846, 227, 227, 3), dtype=np.float32)\n",
    "for i, path in enumerate(image_path_test):\n",
    "    try:\n",
    "        #print(path)\n",
    "        X_test[i,:,:,:] = mpimg.imread(path).astype(float)\n",
    "    except IOError as e:\n",
    "        print('Could not read:', path, ':', e, 'it\\'s ok, skipping.')\n",
    "        print('The index is:', i)\n",
    "\n",
    "dataset = { 'data': X_test,\n",
    "          'labels': labels}\n",
    "\n",
    "pickle.dump(dataset,open(\"Test.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def make_pickle(dataset, file_name):\n",
    "#    try:\n",
    "#        with open(file_name, 'wb') as f:\n",
    "#            pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "#            statinfo = os.stat(file_name)\n",
    "#            print(file_name, 'pickle size:', statinfo.st_size)\n",
    "#    except Exception as e:\n",
    "#        print('Unable to save data to', file_name, ':', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nofimages = labels.shape[0]\n",
    "\n",
    "#for count1 in range(500, nofimages, 500):\n",
    "#    file_name = 'train_dataset_' + str(count1 - 500) + '_' + str(count1) + '.pickle' \n",
    "#    dataset = {'data': X_train[(count1 - 500):count1,:,:],\n",
    "#               'labels': labels[(count1 - 500):count1]\n",
    "#               }\n",
    "#    make_pickle(dataset, file_name)\n",
    "#if count1 < nofimages:\n",
    "#    file_name = 'train_dataset_' + str(count1) + '_' + str(nofimages) + '.pickle' \n",
    "#    dataset = {'data': X_train[count1:nofimages,:,:],\n",
    "#               'labels': labels[count1:nofimages]\n",
    "#               }\n",
    "#    make_pickle(dataset, file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
